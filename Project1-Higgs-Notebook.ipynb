{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from cross_validation import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "oy, otx, oids = load_csv_data('Data/train.csv', False)\n",
    "otest_y, otest_tx, otest_ids= load_csv_data('Data/test.csv', False)\n",
    "\n",
    "#data = pd.read_csv('Data/train.csv', sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#df = data.sample(10)\n",
    "#pd.plotting.scatter_matrix(df, alpha=0.2, diagonal='hist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "b    Axes(0.125,0.125;0.775x0.755)\n",
       "s    Axes(0.125,0.125;0.775x0.755)\n",
       "Name: DER_lep_eta_centrality, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16561d0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data.DER_lep_eta_centrality[~data.DER_lep_eta_centrality.isin([-999.0])].groupby(data.Prediction).hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pd.plotting.scatter_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of w before :  4.90764816114  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.745339294055\n",
      "Size of  w after :  5.79258589138\n",
      "Penalty : % =  0.745339294055   diff :  0.0\n",
      "Size of w before :  4.89309212589  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.746206712484\n",
      "Size of  w after :  5.77744220528\n",
      "Penalty : % =  0.746206712484   diff :  0.0\n",
      "Size of w before :  4.88105702246  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.743204110229\n",
      "Size of  w after :  5.76464789664\n",
      "Penalty : % =  0.743204110229   diff :  0.0\n",
      "Size of w before :  4.87595081759  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.744672049109\n",
      "Size of  w after :  5.75767134168\n",
      "Penalty : % =  0.744672049109   diff :  0.0\n",
      "Size of w before :  4.04535527743  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.641046803535\n",
      "Size of  w after :  4.23840909658\n",
      "Penalty : % =  0.641046803535   diff :  0.0\n",
      "Size of w before :  4.12312191221  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.643024175522\n",
      "Size of  w after :  4.32090608166\n",
      "Penalty : % =  0.643024175522   diff :  0.0\n",
      "Size of w before :  4.03640648486  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.641511056089\n",
      "Size of  w after :  4.22708331902\n",
      "Penalty : % =  0.641511056089   diff :  0.0\n",
      "Size of w before :  4.02729186538  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.645035936587\n",
      "Size of  w after :  4.21851682172\n",
      "Penalty : % =  0.645035936587   diff :  0.0\n",
      "Size of w before :  4.40803989248  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.641762604208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaudpannatier/Documents/EPFL/MLProjects/linear_regression.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  return np.sum(np.log(1+np.exp(tx.dot(w)))-y.T.dot(tx.dot(w)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of  w after :  4.59104938135\n",
      "Penalty : % =  0.487547968771   diff :  -0.154214635437\n",
      "Size of w before :  4.38594775536  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.645732433505\n",
      "Size of  w after :  4.56975347656\n",
      "Penalty : % =  0.489638745534   diff :  -0.156093687971\n",
      "Size of w before :  4.3537651369  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.646976313352\n",
      "Size of  w after :  4.53528890898\n",
      "Penalty : % =  0.49305279873   diff :  -0.153923514622\n",
      "Size of w before :  4.43819368942  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.642080190552\n",
      "Size of  w after :  4.62316152388\n",
      "Penalty : % =  0.486515813153   diff :  -0.155564377398\n",
      "Size of w before :  3.78078842605  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.69776815256\n",
      "Size of  w after :  3.7630141931\n",
      "Penalty : % =  0.69776815256   diff :  0.0\n",
      "Size of w before :  3.65231897333  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.693256331589\n",
      "Size of  w after :  3.63229530658\n",
      "Penalty : % =  0.693196173976   diff :  -6.01576129459e-05\n",
      "Size of w before :  3.58408869695  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.699272092883\n",
      "Size of  w after :  3.56234681524\n",
      "Penalty : % =  0.69921193527   diff :  -6.01576129459e-05\n",
      "Size of w before :  3.59331126961  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.695061059977\n",
      "Size of  w after :  3.57191341746\n",
      "Penalty : % =  0.695061059977   diff :  0.0\n",
      "Number of columns :  2  loss :  41555779792.3 Max of w :  1023.07848845  Percentage of true Y :  0.643257627982\n",
      "Size of w before :  4.17043950373  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.745352638954\n",
      "Size of  w after :  4.6982698052\n",
      "Penalty : % =  0.745339294055   diff :  -1.33448989124e-05\n",
      "Size of w before :  4.16925066003  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.746220057383\n",
      "Size of  w after :  4.69688865763\n",
      "Penalty : % =  0.746206712484   diff :  -1.33448989124e-05\n",
      "Size of w before :  4.1653008037  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.743217455128\n",
      "Size of  w after :  4.69067926687\n",
      "Penalty : % =  0.743204110229   diff :  -1.33448989124e-05\n",
      "Size of w before :  4.07053455161  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.744672049109\n",
      "Size of  w after :  4.59701666043\n",
      "Penalty : % =  0.744672049109   diff :  0.0\n",
      "Size of w before :  3.62129460028  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.6423535885\n",
      "Size of  w after :  3.81469082736\n",
      "Penalty : % =  0.641046803535   diff :  -0.0013067849651\n",
      "Size of w before :  3.69612212551  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.644244987792\n",
      "Size of  w after :  3.89425189373\n",
      "Penalty : % =  0.643024175522   diff :  -0.00122081227002\n",
      "Size of w before :  3.61589286173  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.642817841054\n",
      "Size of  w after :  3.80690938377\n",
      "Penalty : % =  0.641511056089   diff :  -0.0013067849651\n",
      "Size of w before :  3.59938902474  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.646394305169\n",
      "Size of  w after :  3.79096110653\n",
      "Penalty : % =  0.645035936587   diff :  -0.00135836858214\n",
      "Size of w before :  3.46002920977  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.698901680561\n",
      "Size of  w after :  3.67151223786\n",
      "Penalty : % =  0.487547968771   diff :  -0.21135371179\n",
      "Size of w before :  3.43857902857  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.699642715363\n",
      "Size of  w after :  3.64993350936\n",
      "Penalty : % =  0.489638745534   diff :  -0.210003969829\n",
      "Size of w before :  3.39201271704  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.69892814609\n",
      "Size of  w after :  3.60022777892\n",
      "Penalty : % =  0.49305279873   diff :  -0.20587534736\n",
      "Size of w before :  3.45901184635  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.69696969697\n",
      "Size of  w after :  3.6725980046\n",
      "Penalty : % =  0.486515813153   diff :  -0.210453883816\n",
      "Size of w before :  3.04124309061  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.708295734825\n",
      "Size of  w after :  3.02420229634\n",
      "Penalty : % =  0.69776815256   diff :  -0.0105275822655\n",
      "Size of w before :  2.91878389237  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.705769115082\n",
      "Size of  w after :  2.89948769083\n",
      "Penalty : % =  0.693196173976   diff :  -0.0125729411057\n",
      "Size of w before :  2.86030374862  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.71124345786\n",
      "Size of  w after :  2.83927967084\n",
      "Penalty : % =  0.69921193527   diff :  -0.0120315225892\n",
      "Size of w before :  2.88556452814  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.70594958792\n",
      "Size of  w after :  2.86486857413\n",
      "Penalty : % =  0.695061059977   diff :  -0.0108885279432\n",
      "Number of columns :  5  loss :  3.8173856727e+17 Max of w :  10697.8533489  Percentage of true Y :  0.643257627982\n",
      "Size of w before :  3.3699228958  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.745352638954\n",
      "Size of  w after :  3.90166908473\n",
      "Penalty : % =  0.745339294055   diff :  -1.33448989124e-05\n",
      "Size of w before :  3.36973392304  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.746220057383\n",
      "Size of  w after :  3.90126881239\n",
      "Penalty : % =  0.746206712484   diff :  -1.33448989124e-05\n",
      "Size of w before :  3.36741105926  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.743217455128\n",
      "Size of  w after :  3.89665367134\n",
      "Penalty : % =  0.743204110229   diff :  -1.33448989124e-05\n",
      "Size of w before :  3.2959319386  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.744672049109\n",
      "Size of  w after :  3.82629413425\n",
      "Penalty : % =  0.744672049109   diff :  0.0\n",
      "Size of w before :  3.14261399669  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.64271467382\n",
      "Size of  w after :  3.33639866665\n",
      "Penalty : % =  0.641046803535   diff :  -0.0016678702844\n",
      "Size of w before :  3.20848400379  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.644606073111\n",
      "Size of  w after :  3.40701038879\n",
      "Penalty : % =  0.643024175522   diff :  -0.00158189758933\n",
      "Size of w before :  3.14312490007  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.643127342756\n",
      "Size of  w after :  3.33452544851\n",
      "Penalty : % =  0.641511056089   diff :  -0.00161628666735\n",
      "Size of w before :  3.12463276356  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.646635028715\n",
      "Size of  w after :  3.31659180328\n",
      "Penalty : % =  0.645035936587   diff :  -0.00159909212834\n",
      "Size of w before :  2.84925750066  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.701098319439\n",
      "Size of  w after :  3.06133714855\n",
      "Penalty : % =  0.487547968771   diff :  -0.213550350668\n",
      "Size of w before :  2.84883059358  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.699272197962\n",
      "Size of  w after :  3.06112316916\n",
      "Penalty : % =  0.489638745534   diff :  -0.209633452428\n",
      "Size of w before :  2.80248400261  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.697049093556\n",
      "Size of  w after :  3.01102303532\n",
      "Penalty : % =  0.49305279873   diff :  -0.203996294826\n",
      "Size of w before :  2.8489938267  - - - - - - - - - - - - - - - - - - - Per ridge regression :  0.697181421199\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a9617f9bf5ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mmaxW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperGoodI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_clustered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_clustered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mmaxW\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arnaudpannatier/Documents/EPFL/MLProjects/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation_run\u001b[0;34m(tx, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mgoodPer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoodPerI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mrmse_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arnaudpannatier/Documents/EPFL/MLProjects/cross_validation.py\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(y, x, k_indices, k)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mlambda_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mloss_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_logistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mperAfter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpercentageGood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arnaudpannatier/Documents/EPFL/MLProjects/implementations.py\u001b[0m in \u001b[0;36mreg_logistic_regression\u001b[0;34m(y, tx, lambda_, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_reg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gradient_sig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arnaudpannatier/Documents/EPFL/MLProjects/linear_regression.py\u001b[0m in \u001b[0;36mcalculate_reg_loss\u001b[0;34m(y, tx, w, lambda_)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_reg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"compute the cost by negative log likelihood.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_neg_log_like_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_gradient_sig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/arnaudpannatier/Documents/EPFL/MLProjects/linear_regression.py\u001b[0m in \u001b[0;36mcalculate_neg_log_like_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_neg_log_like_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"\"\"compute the cost by negative log likelihood.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_reg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "\n",
    "#for nbColumns in range(2,11):\n",
    "for nbColumns in [2, 5, 10]:\n",
    "    y, tx, ids = oy, otx, oids\n",
    "    test_y, test_tx,test_ids = otest_y, otest_tx, otest_ids\n",
    "    # Preprocessing\n",
    "\n",
    "\n",
    "    PRI_jet_num_colomn_train = tx[:, 22]\n",
    "    PRI_jet_num_colomn_test = test_tx[:, 22]\n",
    "\n",
    "\n",
    "    y_clustered = list()\n",
    "    tx_clustered = list()\n",
    "    ids_clustered = list()\n",
    "    test_y_clustered = list()\n",
    "    test_tx_clustered = list()\n",
    "    test_ids_clustered = list()\n",
    "\n",
    "    for i in range(4):\n",
    "        indices = [ind for ind,a in enumerate(PRI_jet_num_colomn_train) if a == i]\n",
    "        \n",
    "\n",
    "        y_clustered.append(y[indices])\n",
    "        tx_clustered.append(tx[indices])\n",
    "        ids_clustered.append(ids[indices])\n",
    "\n",
    "        test_indices = [ind for ind,a in enumerate(PRI_jet_num_colomn_test) if a == i]\n",
    "        \n",
    "        test_y_clustered.append(test_y[test_indices])\n",
    "        test_tx_clustered.append(test_tx[test_indices])\n",
    "        test_ids_clustered.append(test_ids[test_indices])\n",
    "\n",
    "        #delete colinear columns and preprocess the data\n",
    "        indices_to_delete = list()\n",
    "        for col in range(tx_clustered[i].shape[1]):\n",
    "            if min(tx_clustered[i][:, col]) == max(tx_clustered[i][:, col]):\n",
    "                indices_to_delete.append(col)\n",
    "\n",
    "        deleted_tx = np.delete(tx_clustered[i], indices_to_delete, 1)\n",
    "        tx_clustered[i] = standardizeMatrix(addColumns(deleted_tx, nbColumns))\n",
    "        \n",
    "        deleted_tx = np.delete(test_tx_clustered[i], indices_to_delete, 1)\n",
    "        test_tx_clustered[i] = standardizeMatrix(addColumns(deleted_tx, nbColumns))\n",
    "\n",
    "\n",
    "    # Cross-Validation & Weight computation\n",
    "\n",
    "    from cross_validation import *\n",
    "    w = list()\n",
    "    result = list()\n",
    "    \n",
    "\n",
    "    loss = 0\n",
    "    perGood = 0\n",
    "    maxW = 0\n",
    "    for i in range(4):\n",
    "        wi,loss_te, perGoodI = cross_validation_run(tx_clustered[i], y_clustered[i])\n",
    "        w.append(wi)\n",
    "        maxW += np.max(np.abs(wi))/4\n",
    "        loss += loss_te/4\n",
    "        perGood += perGoodI/4\n",
    "        test_y_clustered[i] = predict_labels(w[i], test_tx_clustered[i])\n",
    "        \n",
    "    print(\"Number of columns : \", nbColumns, \" loss : \", loss, \"Max of w : \", maxW,  \" Percentage of true Y : \", perGood)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using least square on [cst, tx, tx^2, ...] \n",
    "31 - 0.695085425438 \n",
    "\n",
    "61 - 0.776\n",
    "\n",
    "91 - 0.787\n",
    "\n",
    "121 - 0.796\n",
    "\n",
    "151 - 0.805\n",
    "\n",
    "181 - 0.807\n",
    "\n",
    "211 - 0.809\n",
    "\n",
    "241 - 0.816\n",
    "\n",
    "271 - 0.822"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ids = [item for sublist in test_ids_clustered for item in sublist]\n",
    "y_pred = [item for sublist in test_y_clustered for item in sublist]\n",
    "\n",
    "test_ids, y_pred = zip(*sorted(zip(test_ids, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'third-submission'\n",
    "create_csv_submission(test_ids, y_pred, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
