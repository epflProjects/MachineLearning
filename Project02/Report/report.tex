\documentclass[10pt,conference,compsocconf]{IEEEtran}

\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[]{algorithm2e}
\usepackage{placeins}
\usepackage[usenames, dvipsnames]{color}

\begin{document}
\title{Machine Learning - Project 1}
\author{
 Alexander Holloway - Bastian Nanchen - Arnaud Pannatier 
  \\
  \textit{Group : }Max and Lily learn ML \\
  \textit{EPFL 2017}
}
\maketitle

\begin{abstract}
Sentiment classification is an active area of research in the field of machine learning. Here, we present the results of a study into supervised learning methods for classifying the emotional senitment of Tweets -- either positive, or negative -- according to the presence of an emoticon. To this end, we leverage state-of-the-art pre-processing and feature engineering methods, and provide a comparison of learning methods that make use of the resultant features. Finally, we describe in detail the best model we identified for this purpose: \textcolor{blue}{Convolutional neural network, I suppose}, which achieved \textcolor{blue}{x accuracy} on unseen data.
\end{abstract}

\begin{description}
\item[Preprocessing the data] \ \\
List of operation that was used to transform the raw data.
\item[Data] \ \\
Transforming the preprocessed text data into more practical format. 
\item[Classification Methods] \ \\
Description of the different methods that were used as : Logistic regression, CNN, ...
\item[Results] \ \\
Presenation of the results of the differents methods.
\item[Discussion] \ \\
 A comment on the results and possible improvement.  
\end{description}

\input{sec-processing}
\input{sec-data}
\input{sec-methods}
\input{sec-results}
\input{sec-discussion}
\bibliographystyle{IEEEtran}
\bibliography{report}

%\begin{algorithm}[h]
%\DontPrintSemicolon
%\KwData{The CSV file containing the data to classify}
% \KwResult{Predictions}
% Data is clustered into 4 groups as explained in the \textit{Preprocessing and data cleaning} subsection\;
%\For{Degrees up to 13}{
%Feature engineering (extending the matrix with additional degrees) \;
%\For{Each of the 4 groups} {
%\For{Subgroup in cross validation} {
%Select best lambda and apply ridge regression\;
%}
%Remember the best prediction\;
%}
%}
%Recombine the data of all groups\;
%Return the prediction\;
%\end{algorithm}

%\begin{thebibliography}{9}
%\bibitem{CERN}
%Cian O'Luanaigh, \textit{Le centre de données du CERN franchit les 100 pétaoctets} \\
%consulted the 28.10.17 at \url{https://home.cern/fr/about/updates/2013/02/cern-data-centre-passes-100-petabytes}
%\end{thebibliography}

\end{document}
